{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install transformers"
      ],
      "metadata": {
        "id": "NrzNxUZU95Zp"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "pRfNOJro9UHE"
      },
      "outputs": [],
      "source": [
        "## KoBERT를 이용하여 korNLI(Natural Language Inference)문제 해결\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련데이터\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kakaobrain/KorNLUDatasets/master/KorNLI/multinli.train.ko.tsv\", filename=\"multinli.train.ko.tsv\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kakaobrain/KorNLUDatasets/master/KorNLI/snli_1.0_train.ko.tsv\", filename=\"snli_1.0_train.ko.tsv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHf0XQU1-Hs2",
        "outputId": "e6a717c3-bc10-4679-97fb-741118ea3075"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('snli_1.0_train.ko.tsv', <http.client.HTTPMessage at 0x7ddf2a8c6f20>)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증데이터\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kakaobrain/KorNLUDatasets/master/KorNLI/xnli.dev.ko.tsv\", filename=\"xnli.dev.ko.tsv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYC069z7-Hn7",
        "outputId": "42b657cf-5623-4d8a-9fb0-481ed21a8771"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('xnli.dev.ko.tsv', <http.client.HTTPMessage at 0x7ddf2ade4e80>)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kakaobrain/KorNLUDatasets/master/KorNLI/xnli.test.ko.tsv\", filename=\"xnli.test.ko.tsv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im3-COXD9wkr",
        "outputId": "303e274e-ce2b-4ebb-b371-39aac9eb1078"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('xnli.test.ko.tsv', <http.client.HTTPMessage at 0x7ddf2a8c5060>)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quoting : 인용부호제거\n",
        "train_snli = pd.read_csv(\"snli_1.0_train.ko.tsv\", sep='\\t', quoting=3)\n",
        "train_xnli = pd.read_csv(\"multinli.train.ko.tsv\", sep='\\t', quoting=3)\n",
        "val_data = pd.read_csv(\"xnli.dev.ko.tsv\", sep='\\t', quoting=3)\n",
        "test_data = pd.read_csv(\"xnli.test.ko.tsv\", sep='\\t', quoting=3)"
      ],
      "metadata": {
        "id": "oUAwQbuM-gYq"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_snli.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "ZQtEvDY5-oL9",
        "outputId": "dbfccc21-43f0-4105-d20c-591462dd04d0"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    sentence1                  sentence2     gold_label\n",
              "0  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.  한 사람이 경쟁을 위해 말을 훈련시키고 있다.        neutral\n",
              "1  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   한 사람이 식당에서 오믈렛을 주문하고 있다.  contradiction\n",
              "2  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.         사람은 야외에서 말을 타고 있다.     entailment\n",
              "3          카메라에 웃고 손을 흔드는 아이들          그들은 부모님을 보고 웃고 있다        neutral\n",
              "4          카메라에 웃고 손을 흔드는 아이들                    아이들이 있다     entailment"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ff8645fe-f44a-443e-93a5-a84c5a034700\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
              "      <td>한 사람이 경쟁을 위해 말을 훈련시키고 있다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
              "      <td>한 사람이 식당에서 오믈렛을 주문하고 있다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
              "      <td>사람은 야외에서 말을 타고 있다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
              "      <td>그들은 부모님을 보고 웃고 있다</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
              "      <td>아이들이 있다</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff8645fe-f44a-443e-93a5-a84c5a034700')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-672b6805-41e4-414e-84ce-f0d946c131d1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-672b6805-41e4-414e-84ce-f0d946c131d1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-672b6805-41e4-414e-84ce-f0d946c131d1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff8645fe-f44a-443e-93a5-a84c5a034700 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff8645fe-f44a-443e-93a5-a84c5a034700');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_snli.append(train_xnli)\n",
        "train_data = train_data.sample(frac=1) #데이터 섞음\n",
        "train_data = train_data.iloc[:30000]\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "RJohhAVC-7Yf",
        "outputId": "715105ee-1b18-49f8-bc98-e95724a37751"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-160-58762036e2bd>:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  train_data = train_snli.append(train_xnli)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sentence1  \\\n",
              "545723  파란색 \"LABOR DAY 2010\" 셔츠를 입은 많은 사람들이 거리를 걷고, 전경...   \n",
              "513842            두 남자가 거리에 서 있는데, 한 남자가 뭔가를 던지고 있는 것 같다.   \n",
              "93760                                  콘크리트를 매끄럽게 하는 벽돌공.   \n",
              "355614    연방 기관에 도전하는 주요 분야 중 하나는 결과 지향적인 조직 문화를 만드는 것이다.   \n",
              "14632   한 할머니와 한 아이가 아프리카 사람에 의해 음식을 제공받는 동안 화려한 녹색 테이...   \n",
              "\n",
              "                                                sentence2     gold_label  \n",
              "545723                            그 어린 소년은 어머니의 어깨 위에 있다.  contradiction  \n",
              "513842                           두 남자가 식당에 앉아 식사를 즐기고 있다.  contradiction  \n",
              "93760                                     사람이 실수를 고치고 있다.        neutral  \n",
              "355614  연방 기관의 핵심 분야 중 하나는 이해당사자들 사이에 결과 지향적인 문화를 만드는 ...        neutral  \n",
              "14632                                 두 남자가 BBQ 갈비를 먹고 있다  contradiction  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-07300987-641a-4cd0-9dc5-0dc15ed3f4ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>545723</th>\n",
              "      <td>파란색 \"LABOR DAY 2010\" 셔츠를 입은 많은 사람들이 거리를 걷고, 전경...</td>\n",
              "      <td>그 어린 소년은 어머니의 어깨 위에 있다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513842</th>\n",
              "      <td>두 남자가 거리에 서 있는데, 한 남자가 뭔가를 던지고 있는 것 같다.</td>\n",
              "      <td>두 남자가 식당에 앉아 식사를 즐기고 있다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93760</th>\n",
              "      <td>콘크리트를 매끄럽게 하는 벽돌공.</td>\n",
              "      <td>사람이 실수를 고치고 있다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355614</th>\n",
              "      <td>연방 기관에 도전하는 주요 분야 중 하나는 결과 지향적인 조직 문화를 만드는 것이다.</td>\n",
              "      <td>연방 기관의 핵심 분야 중 하나는 이해당사자들 사이에 결과 지향적인 문화를 만드는 ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14632</th>\n",
              "      <td>한 할머니와 한 아이가 아프리카 사람에 의해 음식을 제공받는 동안 화려한 녹색 테이...</td>\n",
              "      <td>두 남자가 BBQ 갈비를 먹고 있다</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07300987-641a-4cd0-9dc5-0dc15ed3f4ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-5a083042-6967-4a43-a9f9-8202cb36efcb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a083042-6967-4a43-a9f9-8202cb36efcb')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-5a083042-6967-4a43-a9f9-8202cb36efcb button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07300987-641a-4cd0-9dc5-0dc15ed3f4ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07300987-641a-4cd0-9dc5-0dc15ed3f4ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_na_and_duplciates(df):\n",
        "  df = df.dropna()\n",
        "  df = df.drop_duplicates()\n",
        "  df = df.reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "DpD1YBmQ_a2c"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값 및 중복 샘플 제거\n",
        "train_data = drop_na_and_duplciates(train_data)\n",
        "val_data = drop_na_and_duplciates(val_data)\n",
        "test_data = drop_na_and_duplciates(test_data)\n",
        "\n",
        "print('훈련용 샘플 개수 :',len(train_data))\n",
        "print('검증용 샘플 개수 :',len(val_data))\n",
        "print('테스트용 샘플 개수 :',len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBMOoLaq_tJc",
        "outputId": "4983998c-986a-4e40-a28c-c35ea9de3c29"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 샘플 개수 : 29998\n",
            "검증용 샘플 개수 : 2490\n",
            "테스트용 샘플 개수 : 5010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")"
      ],
      "metadata": {
        "id": "QYaYbtEaADIG"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = train_data['sentence1'].iloc[0]\n",
        "sent2 = train_data['sentence2'].iloc[0]\n",
        "print(sent1)\n",
        "print(sent2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrv8mcscAOjC",
        "outputId": "74c5620d-d011-4cb7-e318-a7558752c855"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파란색 \"LABOR DAY 2010\" 셔츠를 입은 많은 사람들이 거리를 걷고, 전경에 있는 3명은 유모차를 가진 여성과 어린 소년을 어깨에 메고 있는 남성을 포함합니다.\n",
            "그 어린 소년은 어머니의 어깨 위에 있다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 128\n",
        "encoding_result = tokenizer.encode_plus(sent1, sent2, max_length=max_seq_len, pad_to_max_length=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAOjxMLyATnV",
        "outputId": "322d45d3-fc98-4209-f9ab-749dc38712e2"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(sent_list1, sent_list2, max_seq_len, tokenizer):\n",
        "    input_ids, attention_masks, token_type_ids = [], [], []\n",
        "\n",
        "    for sent1, sent2 in tqdm(zip(sent_list1, sent_list2), total=len(sent_list1)):\n",
        "\n",
        "        encoding_result = tokenizer.encode_plus(sent1, sent2, max_length=max_seq_len, pad_to_max_length=True)\n",
        "\n",
        "        input_ids.append(encoding_result['input_ids'])\n",
        "        attention_masks.append(encoding_result['attention_mask'])\n",
        "        token_type_ids.append(encoding_result['token_type_ids'])\n",
        "\n",
        "    input_ids = np.array(input_ids, dtype=int)\n",
        "    attention_masks = np.array(attention_masks, dtype=int)\n",
        "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
        "\n",
        "    return (input_ids, attention_masks, token_type_ids)"
      ],
      "metadata": {
        "id": "L4rtLeYtA0HN"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = convert_examples_to_features(train_data['sentence1'], train_data['sentence2'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S9UShdxCGhu",
        "outputId": "7581a64e-c384-44f2-d2f1-1b310ecbf4c8"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 2901/29998 [00:01<00:13, 2035.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 12%|█▏        | 3522/29998 [00:01<00:13, 1990.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 16%|█▌        | 4771/29998 [00:02<00:12, 2071.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 20%|██        | 6038/29998 [00:03<00:11, 2085.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 24%|██▍       | 7328/29998 [00:03<00:11, 2031.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 25%|██▌       | 7536/29998 [00:03<00:10, 2043.78it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 27%|██▋       | 7954/29998 [00:03<00:10, 2051.06it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 27%|██▋       | 8160/29998 [00:04<00:10, 1991.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 29%|██▊       | 8579/29998 [00:04<00:10, 2043.87it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 30%|██▉       | 8988/29998 [00:04<00:10, 1923.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 31%|███▏      | 9397/29998 [00:04<00:10, 1942.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 34%|███▍      | 10237/29998 [00:05<00:09, 2035.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 38%|███▊      | 11507/29998 [00:05<00:09, 1984.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 39%|███▉      | 11708/29998 [00:05<00:09, 1990.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 43%|████▎     | 12787/29998 [00:06<00:13, 1245.01it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 43%|████▎     | 12913/29998 [00:06<00:14, 1187.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 44%|████▍     | 13157/29998 [00:07<00:14, 1184.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 44%|████▍     | 13276/29998 [00:07<00:14, 1176.75it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 45%|████▍     | 13394/29998 [00:07<00:14, 1154.87it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 47%|████▋     | 14121/29998 [00:07<00:13, 1168.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 48%|████▊     | 14362/29998 [00:08<00:13, 1136.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 49%|████▉     | 14829/29998 [00:08<00:13, 1147.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 50%|████▉     | 14945/29998 [00:08<00:13, 1135.36it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 50%|█████     | 15059/29998 [00:08<00:13, 1100.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 51%|█████     | 15170/29998 [00:08<00:13, 1086.69it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 53%|█████▎    | 15787/29998 [00:09<00:11, 1224.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 53%|█████▎    | 16032/29998 [00:09<00:11, 1202.03it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 54%|█████▍    | 16153/29998 [00:09<00:11, 1166.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 57%|█████▋    | 17225/29998 [00:12<01:05, 193.58it/s] Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 59%|█████▉    | 17657/29998 [00:12<00:25, 477.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 62%|██████▏   | 18498/29998 [00:12<00:09, 1231.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 63%|██████▎   | 18895/29998 [00:13<00:07, 1480.08it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 65%|██████▌   | 19524/29998 [00:13<00:05, 1855.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 66%|██████▋   | 19943/29998 [00:13<00:05, 1879.32it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 67%|██████▋   | 20141/29998 [00:13<00:05, 1878.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 70%|██████▉   | 20944/29998 [00:14<00:04, 1963.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 71%|███████   | 21149/29998 [00:14<00:04, 1985.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 71%|███████   | 21349/29998 [00:14<00:04, 1939.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 77%|███████▋  | 23030/29998 [00:15<00:03, 2030.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 78%|███████▊  | 23459/29998 [00:15<00:03, 2081.35it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 79%|███████▉  | 23668/29998 [00:15<00:03, 2073.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 80%|███████▉  | 23876/29998 [00:15<00:03, 2038.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 80%|████████  | 24081/29998 [00:15<00:02, 2021.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 84%|████████▍ | 25298/29998 [00:16<00:02, 1948.35it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 85%|████████▌ | 25502/29998 [00:16<00:02, 1974.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 86%|████████▋ | 25906/29998 [00:16<00:02, 1980.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 87%|████████▋ | 26105/29998 [00:16<00:02, 1875.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 88%|████████▊ | 26308/29998 [00:16<00:01, 1916.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 89%|████████▉ | 26718/29998 [00:17<00:01, 1964.13it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 90%|████████▉ | 26916/29998 [00:17<00:01, 1956.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 91%|█████████ | 27314/29998 [00:17<00:01, 1968.21it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 96%|█████████▌| 28794/29998 [00:18<00:01, 1072.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "100%|██████████| 29998/29998 [00:19<00:00, 1520.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q29ybjupCHw3",
        "outputId": "6bc13a33-beb3-4c96-c4b6-3c1c2e2aeaa8"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[    2, 18280,     6, ...,     0,     0,     0],\n",
              "        [    2,   864,  3997, ...,     0,     0,     0],\n",
              "        [    2, 12875,  2138, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,  1891,  4030, ...,     0,     0,     0],\n",
              "        [    2,  3633,  2028, ...,     0,     0,     0],\n",
              "        [    2,  5950,  2052, ...,     0,     0,     0]]),\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. KoGPT를 이용하여 문장을 생성하시오.\n",
        "\n",
        "2.\n",
        "분류기 -> OKT 형태소 분석 -> 의미없는 품사 제거(성능 높이는 방향) -> 모델"
      ],
      "metadata": {
        "id": "Pa13y-pZF1g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이: 128\n",
        "input_id = X_train[0][0]\n",
        "attention_mask = X_train[1][0]\n",
        "token_type_id = X_train[2][0]\n",
        "\n",
        "print('단어에 대한 정수 인코딩 :',input_id)\n",
        "print('어텐션 마스크 :',attention_mask) #CLS\n",
        "print('세그먼트 인코딩 :',token_type_id) #SEP\n",
        "print('각 인코딩의 길이 :', len(input_id))\n",
        "print('정수 인코딩 복원 :',tokenizer.decode(input_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4YNcMJWFUZ7",
        "outputId": "5b5d98b7-1e8c-4a3b-f134-da35946ff462"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어에 대한 정수 인코딩 : [    2 18280     6  9937  2206 14851 27585  2214  4690     6 10727  2138\n",
            "  1511  2073  1039  2073  3611  7285  4142  2138   571  2088    16 10846\n",
            "  2170  1513  2259    23  2211  2073 20109  2138  4398  3811  2145  4030\n",
            "  5950  2069  5463  2170  1065  2088  1513  2259  4576  2069  3954 11800\n",
            "    18     3   636  4030  5950  2073  4226  2079  5463  1485  2170  1513\n",
            "  2062    18     3     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "각 인코딩의 길이 : 128\n",
            "정수 인코딩 복원 : [CLS] 파란색 \" LABOR DAY 2010 \" 셔츠를 입은 많은 사람들이 거리를 걷고, 전경에 있는 3명은 유모차를 가진 여성과 어린 소년을 어깨에 메고 있는 남성을 포함합니다. [SEP] 그 어린 소년은 어머니의 어깨 위에 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = convert_examples_to_features(val_data['sentence1'], val_data['sentence2'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm2KhJNVHKS9",
        "outputId": "23bea4a6-bebe-4211-d72b-52de15168ce9"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2490/2490 [00:03<00:00, 691.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이: 128\n",
        "input_id = X_val[0][0]\n",
        "attention_mask = X_val[1][0]\n",
        "token_type_id = X_val[2][0]\n",
        "print('단어에 대한 정수 인코딩 :',input_id)\n",
        "print('어텐션 마스크 :',attention_mask)\n",
        "print('세그먼트 인코딩 :',token_type_id)\n",
        "print('각 인코딩의 길이 :', len(input_id))\n",
        "print('정수 인코딩 복원 :',tokenizer.decode(input_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GQ0t5rFHhb0",
        "outputId": "21bb1d7a-88a5-4217-eeb8-d3165384ecc2"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어에 대한 정수 인코딩 : [    2  3673   636  2116  1041  2371  2062    16     6  4122    16  1535\n",
            "  1458 10283    18     6     3   636  2259  3741  4942  2116   636  2138\n",
            "  4105  2223  2155  6000  4122  2170  2318  4117  2138   572  2359  2062\n",
            "    18     3     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "각 인코딩의 길이 : 128\n",
            "정수 인코딩 복원 : [CLS] 그리고 그가 말했다, \" 엄마, 저 왔어요. \" [SEP] 그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = convert_examples_to_features(test_data['sentence1'], test_data['sentence2'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBJWC09uHlPB",
        "outputId": "9cc8d5bd-cb48-4ed8-e081-f22c01c343cf"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5010/5010 [00:07<00:00, 663.78it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이: 128\n",
        "input_id = X_test[0][0]\n",
        "attention_mask = X_test[1][0]\n",
        "token_type_id = X_test[2][0]\n",
        "print('단어에 대한 정수 인코딩 :',input_id)\n",
        "print('어텐션 마스크 :',attention_mask)\n",
        "print('세그먼트 인코딩 :',token_type_id)\n",
        "print('각 인코딩의 길이 :', len(input_id))\n",
        "print('정수 인코딩 복원 :',tokenizer.decode(input_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmSKrZt9HoHI",
        "outputId": "52265b50-a08d-47a5-dabd-d456cb26437b"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어에 대한 정수 인코딩 : [   2 8911   16  717 2259 3724 2170 9149 3628 2446 2232 1889 2118 1380\n",
            " 2886 3683   16  717 2259 3760 8642 2371 2088   16 3983  636 2170 2318\n",
            " 3690 3758 2205 2318  859 2359 2062   18    3  717 2259  636 2522 3690\n",
            " 3758 2205 2118 1380 2886 2062   18    3    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "각 인코딩의 길이 : 128\n",
            "정수 인코딩 복원 : [CLS] 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. [SEP] 나는 그와 다시 이야기하지 않았다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = train_data['gold_label'].tolist()\n",
        "val_label = val_data['gold_label'].tolist()\n",
        "test_label = test_data['gold_label'].tolist()"
      ],
      "metadata": {
        "id": "rAYv0_EqHxzB"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 -> 카테고리화 할 때 사용.\n",
        "#pd.get_dummies()\n",
        "#LabelEncoder()\n",
        "\n",
        "idx_encode = preprocessing.LabelEncoder()\n",
        "idx_encode.fit(train_label)\n",
        "\n",
        "y_train = idx_encode.transform(train_label) # 주어진 고유한 정수로 변환\n",
        "y_val = idx_encode.transform(val_label) # 고유한 정수로 변환\n",
        "y_test = idx_encode.transform(test_label) # 고유한 정수로 변환"
      ],
      "metadata": {
        "id": "GXOWI_8oH3QR"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_idx = dict(zip(list(idx_encode.classes_), idx_encode.transform(list(idx_encode.classes_))))"
      ],
      "metadata": {
        "id": "168Tuad7IOtd"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_encode.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmYHEjxRIVsj",
        "outputId": "02bf8310-7230-499c-fa24-af4a1b96471b"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['contradiction', 'entailment', 'neutral'], dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_label = {value: key for key, value in label_idx.items()}\n",
        "\n",
        "print(label_idx)\n",
        "print(idx_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CLIy7FOIkCH",
        "outputId": "a8e6cd37-4aae-44a9-89c5-8f8d9525d078"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'contradiction': 0, 'entailment': 1, 'neutral': 2}\n",
            "{0: 'contradiction', 1: 'entailment', 2: 'neutral'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TFBertForSequenceClassification(tf.keras.Model):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super(TFBertForSequenceClassification, self).__init__()\n",
        "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
        "        self.classifier = tf.keras.layers.Dense(num_labels,\n",
        "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
        "                                                activation='softmax',\n",
        "                                                name='classifier')\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask, token_type_ids = inputs\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        cls_token = outputs[1]\n",
        "        prediction = self.classifier(cls_token)\n",
        "        return prediction\n",
        "\n",
        "# TPU 작동을 위한 코드 TPU 작동을 위한 코드\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLpJo_6qIqBK",
        "outputId": "f94eb014-f94c-4d2a-a914-39414b732de4"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.99.126.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7ddf2e16dde0>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II_iFM53I3wg",
        "outputId": "77255dd9-bd3b-4aa1-cb02-17b9ece07ac6"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = TFBertForSequenceClassification(\"klue/bert-base\", num_labels=3)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utkSni90I11G",
        "outputId": "c15277c4-38d2-409f-f53a-638262ec385b"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    min_delta=0.001,\n",
        "    patience=2)\n",
        "model.fit(\n",
        "    X_train, y_train, epochs=10, batch_size=32, validation_data = (X_val, y_val),\n",
        "    callbacks = [early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6VzqQ9RI9ZP",
        "outputId": "8a1ed55b-29f0-4d67-fe91-d2d5a4379099"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 215s 136ms/step - loss: 0.7468 - accuracy: 0.6791 - val_loss: 0.6906 - val_accuracy: 0.7133\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 76s 81ms/step - loss: 0.4728 - accuracy: 0.8219 - val_loss: 0.7362 - val_accuracy: 0.7141\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 76s 81ms/step - loss: 0.2758 - accuracy: 0.9030 - val_loss: 0.8247 - val_accuracy: 0.7217\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 76s 81ms/step - loss: 0.1678 - accuracy: 0.9450 - val_loss: 1.0384 - val_accuracy: 0.7048\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 76s 81ms/step - loss: 0.1225 - accuracy: 0.9597 - val_loss: 1.0508 - val_accuracy: 0.7193\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ddf2c58d300>"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test, batch_size=512)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R9p-VbJJG8w",
        "outputId": "58f2252e-380b-4057-ad5e-c8a25712aad0"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 13s 724ms/step - loss: 1.0534 - accuracy: 0.7036\n",
            "\n",
            " 테스트 정확도: 0.7036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xEGqdEtTmd6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 가져옴\n",
        "\n",
        "def sentiment_predict(new_sentence) :\n",
        "  #긍/부정 분류\n",
        "  input_id = tokenizer.encode(new_sentence, max_length=max_seq_len, pad_to_max_length=True)\n",
        "\n",
        "  padding_count = input_id.count(tokenizer.pad_token_id)\n",
        "  attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
        "  token_type_id = [0] * max_seq_len\n",
        "\n",
        "  #그대로 사용 못해서 array로 바꿔줌\n",
        "  input_ids = np.array([input_id])\n",
        "  attention_masks = np.array([attention_mask])\n",
        "  token_type_ids = np.array([token_type_id])\n",
        "\n",
        "  encoded_input = [input_ids, attention_masks, token_type_ids]\n",
        "  score = model.predict(encoded_input)[0][0]\n",
        "\n",
        "  print(score)\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
      ],
      "metadata": {
        "id": "utwMamgeys42"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_predict(\"긍,부정 왤케 분류 못함? 왜이럼?\"))\n",
        "print(sentiment_predict(\"안아줘요\"))\n",
        "print(sentiment_predict(\"...\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_hUUrfP2Cfa",
        "outputId": "1bf2f336-64af-4e36-a1c6-ede615248039"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 9s 9s/step\n",
            "0.49188676\n",
            "50.81% 확률로 부정 리뷰입니다.\n",
            "\n",
            "None\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "0.6597662\n",
            "65.98% 확률로 긍정 리뷰입니다.\n",
            "\n",
            "None\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "0.09337331\n",
            "90.66% 확률로 부정 리뷰입니다.\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qiitL732GQv"
      },
      "execution_count": 185,
      "outputs": []
    }
  ]
}