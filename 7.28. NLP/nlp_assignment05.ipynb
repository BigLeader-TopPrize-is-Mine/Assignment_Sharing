{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZaAV9m_RkVH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "otUf6tlsTSar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_table('/content/drive/MyDrive/bigleader/shopping.txt')"
      ],
      "metadata": {
        "id": "qlZgjTB_TJ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns = ['score', 'content']"
      ],
      "metadata": {
        "id": "_DV4WWN0U6Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "CK6lmEjjV_Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['score']=data['score'].replace([1,2,4,5],[0,0,1,1])"
      ],
      "metadata": {
        "id": "towK-jThWKFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "mz8BUyuvWdJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()\n",
        "data.describe()\n",
        "data.score.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mQ5jnrYWz55",
        "outputId": "2838f714-c0f6-41c6-aa44-36f146f00e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 199999 entries, 0 to 199998\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   score    199999 non-null  int64 \n",
            " 1   content  199999 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    100037\n",
              "1     99962\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['content'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6s6bxpHWx-v",
        "outputId": "b986fb0a-67fc-47e2-81b3-aa76392524f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199907"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset=['content'], inplace=True)"
      ],
      "metadata": {
        "id": "PnhSHTcnXJOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfMxXd9ZXMJN",
        "outputId": "a6819d6b-ac5c-441c-84c4-f74fc4bb638f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199907"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ydata=data['score']\n",
        "xdata=data['content']"
      ],
      "metadata": {
        "id": "41TJjAMTXcPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install konlpy"
      ],
      "metadata": {
        "id": "PVLPO4yhbsZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt=Okt()\n",
        "\n",
        "stop_words = [\n",
        "    '아', '휴', '아이구', '아이쿠', '아이고', '어', '나', '우리', '저희', '따라', '의해', '을', '를', '에', '의', '가',\n",
        "    '으로', '로', '에게', '뿐이다', '의거하여', '근거하여', '입각하여', '기준으로', '예하면', '예를 들면', '예를 들자면', '저',\n",
        "    '소인', '소생', '저희', '지말고', '하지마', '하지마라', '다른', '물론', '또한', '그리고', '그런데', '하지만', '만일', '위하여',\n",
        "    '하여야', '비하면', '시키다', '하게하다', '하게 되다', '놓다', '있다', '그렇다', '크다', '작다', '같다', '말하다', '생각하다',\n",
        "    '느끼다', '그러나', '그런', '한', '다른', '다른', '더러', '잠깐', '하다가', '이렇게', '그때', '이런', '저런', '따위', '것',\n",
        "    '것들', '무엇', '무슨', '어느', '어떤', '언제', '어디', '어느', '어떻게', '얼마', '여기', '기점으로', '기점에서', '빨리',\n",
        "    '거의', '하물며', '이래', '그래', '다만', '만약', '하니', '정도', '하먼', '힘입어', '험차', '남짓', '할지라도', '말할것도 없고',\n",
        "    '할망정', '하면', '할수록', '주룩주룩', '지든지', '할지언정', '할지라도', '지든지', '더군다나', '거창', '만 못하다', '할 따름이다',\n",
        "    '말할것도 없고', '무릎쓰고', '개의치 않고', '하는 김에', '겁쟁이를', '깨고', '부르짖고', '놀래키고', '힘입어', '험차', '남짓',\n",
        "    '눈을 감고', '더욱더', '불구하고', '얼마든지', '마음대로', '주저하지 않고', '당장', '하자마자', '바로', '당장', '하면된다',\n",
        "    '즉시', '바로', '하면', '될것이다', '그래', '그렇지', '요컨대', '다시 말하자면', '바꿔 말하면', '즉', '구체적으로', '말하자면',\n",
        "    '시작하여', '시초에', '이상', '과 같은', '관계가 있다', '관련이 있다', '연관되다', '어떤', '에 대해', '이러한', '에 따르면',\n",
        "    '에 있다', '이것', '이것들', '여러분','이렇게', '전혀', '모두', '아무',\n",
        "    '어느', '또한', '심지어', '조차', '한켠으로는', '그중에서', '본대로', '자', '이', '여', '여야', '여도', '하도록시키다', '하기 위하여',\n",
        "    '위해서', '때문에', '아야', '하곤하였다', '다른', '다른', '뛰어난', '특별한', '얼마', '하느니', '하면 할수록', '일', '하면서',\n",
        "    '자마자', '하자마자', '둘째, 더욱더', '더욱이는', '뿐만 아니라', '그렇지 않으면', '그렇지 않다면', '그렇지', '않으면', '안', '그러나',\n",
        "    '그렇지만', '이렇지만', '아니면', '반대로', '말하자면', '바꾸어서 말하면', '하나', '이', '일', '허', '하', '바', '바',\n",
        "    '제', '가', '은', '는', '와', '과', '도', '의', '에게', '에게서', '뿐이다', '에게서', '으로서', '보는',\n",
        "    '것', '과의', '보다', '된', '의해', '할', '것이다', '같다', '했다', '해야한다', '한다', '해야한다', '되는', '된다'\n",
        "]\n",
        "\n",
        "tok_data=[]\n",
        "\n",
        "for content in xdata :\n",
        "  tok_sent=okt.morphs(content)\n",
        "  sw_rem_sent=[w for w in tok_sent if not w in stop_words]\n",
        "  tok_data.append(sw_rem_sent)\n",
        "\n",
        "print(tok_data[0], tok_data[1], tok_data[2], tok_data[3], tok_data[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOM4TIbKaFqE",
        "outputId": "78dc5b18-5493-46d3-ee48-de282b22b524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! --NotebookApp.iopub_data_rate_limit=1000000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5fQVhlKduNc",
        "outputId": "226e7e72-91cc-40c6-dfbd-5dbff85a1b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: --NotebookApp.iopub_data_rate_limit=1000000000: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#층화추출:종류에따라 균등하게 분리하여 추출\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(tok_data,ydata,test_size=0.2,\n",
        "                                              random_state=902,\n",
        "                                              stratify=ydata)"
      ],
      "metadata": {
        "id": "Gin5NxXxapuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok=Tokenizer()\n",
        "tok.fit_on_texts(xtrain) #xtrain를 코퍼스로하여 fitting(단어별로 index가 부여됨)\n",
        "xtrain_enc=tok.texts_to_sequences(xtrain)\n",
        "\n",
        "tok.index_word\n",
        "w2i=tok.word_index\n",
        "\n",
        "type(xtrain_enc)\n",
        "xtrain_enc\n",
        "sum(map(len, xtrain_enc))/len(xtrain_enc) #메일의 평균 단어 갯수\n",
        "\n",
        "max(map(len, xtrain_enc)) #메일의 최대 단어 갯수\n",
        "min(map(len, xtrain_enc))#메일의 최대 단어 갯수\n",
        "\n",
        "maxLen=max(len(s) for s in xtrain_enc)\n",
        "\n",
        "xtrain_padded=pad_sequences(xtrain_enc, maxlen=maxLen)\n",
        "\n",
        "vocab_size=len(w2i)+1"
      ],
      "metadata": {
        "id": "H8FZDsjxosZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 32))\n",
        "model.add(SimpleRNN(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(xtrain_padded, ytrain, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "xtest_enc=tok.texts_to_sequences(xtest)\n",
        "xtest_padded=pad_sequences(xtest_enc, maxlen=maxLen)\n",
        "#model.predict(xtest_padded)\n",
        "model.evaluate(xtest_padded,ytest)\n",
        "model.evaluate(xtest_padded,ytest)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a14QjsToxqb",
        "outputId": "fb7f9e5d-15f9-40e0-9052-2517eca63ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3999/3999 [==============================] - 207s 50ms/step - loss: 0.3212 - accuracy: 0.8715 - val_loss: 0.2721 - val_accuracy: 0.8977\n",
            "Epoch 2/5\n",
            "3999/3999 [==============================] - 194s 48ms/step - loss: 0.2927 - accuracy: 0.8880 - val_loss: 0.2883 - val_accuracy: 0.8918\n",
            "Epoch 3/5\n",
            "3999/3999 [==============================] - 194s 48ms/step - loss: 0.2945 - accuracy: 0.8878 - val_loss: 0.3081 - val_accuracy: 0.8835\n",
            "Epoch 4/5\n",
            "3999/3999 [==============================] - 204s 51ms/step - loss: 0.2740 - accuracy: 0.8976 - val_loss: 0.3523 - val_accuracy: 0.8498\n",
            "Epoch 5/5\n",
            "3999/3999 [==============================] - 195s 49ms/step - loss: 0.2504 - accuracy: 0.9084 - val_loss: 0.2573 - val_accuracy: 0.9075\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.2570 - accuracy: 0.9073\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2570 - accuracy: 0.9073\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9072582721710205"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}